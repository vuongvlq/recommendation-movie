{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b61a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e1efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91f193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim, Tensor\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn import LGConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e0dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MovieLens dataset\n",
    "ratings = pd.read_csv('./dataset/ml-latest-small/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "714f14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map user and movie IDs to indices\n",
    "user_map = {user_id: i for i, user_id in enumerate(ratings['userId'].unique())}\n",
    "movie_map = {movie_id: i for i, movie_id in enumerate(ratings['movieId'].unique())}\n",
    "\n",
    "# Count the number of users, movies and total entities in the dataset\n",
    "num_users = len(user_map)\n",
    "num_movies = len(movie_map)\n",
    "num_total = num_users + num_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eba3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor for user and movie indices based on the user ratings in the dataset\n",
    "user_ids = torch.LongTensor([user_map[user_id] for user_id in ratings['userId']])\n",
    "movie_ids = torch.LongTensor([movie_map[movie_id] for movie_id in ratings['movieId']])\n",
    "edge_index = torch.stack([user_ids, movie_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "782bfc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "train_index, test_index = train_test_split(range(len(ratings)), test_size=0.2, random_state=0)\n",
    "val_index, test_index = train_test_split(test_index, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9003981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_index = edge_index[:, train_index]\n",
    "val_edge_index = edge_index[:, val_index]\n",
    "test_edge_index = edge_index[:, test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "479d9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a batch of random indices using np.random.choice\n",
    "def sample_mini_batch(edge_index):\n",
    "  index = np.random.choice(range(edge_index.shape[1]), size=BATCH_SIZE)\n",
    "\n",
    "  # Generate negative samples\n",
    "  edge_index = structured_negative_sampling(edge_index)\n",
    "  edge_index = torch.stack(edge_index, dim=0)\n",
    "\n",
    "  # Select the user, positive and negative samples\n",
    "  user_index = edge_index[0, index]\n",
    "  pos_movie_index = edge_index[1, index]\n",
    "  neg_movie_index = edge_index[2, index]\n",
    "\n",
    "  return user_index, pos_movie_index, neg_movie_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26810866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGCN Model\n",
    "class LightGCN(nn.Module):\n",
    "  def __init__(self, num_users, num_movies, num_layers=4, dim_h=64):\n",
    "    super().__init__()\n",
    "    self.num_users = num_users\n",
    "    self.num_movies = num_movies\n",
    "    self.num_layers = num_layers\n",
    "    self.emb_users = nn.Embedding(num_embeddings=self.num_users, embedding_dim=dim_h)\n",
    "    self.emb_movies = nn.Embedding(num_embeddings=self.num_movies, embedding_dim=dim_h)\n",
    "    self.convs = nn.ModuleList(LGConv() for _ in range(num_layers))\n",
    "\n",
    "    # Initialize the weights\n",
    "    nn.init.normal_(self.emb_users.weight, std=0.1)\n",
    "    nn.init.normal_(self.emb_movies.weight, std=0.1)\n",
    "\n",
    "  def forward(self, edge_index):\n",
    "    emb = torch.cat([self.emb_users.weight, self.emb_movies.weight])\n",
    "    embs = [emb]\n",
    "    for conv in self.convs:\n",
    "      emb = conv(x=emb, edge_index=edge_index)\n",
    "      embs.append(emb)\n",
    "    \n",
    "    emb_final = torch.mean(torch.stack(embs, dim=1), dim=1)\n",
    "    \n",
    "    emb_users_final, emb_movies_final = torch.split(emb_final, [self.num_users, self.num_movies])\n",
    "    return emb_users_final, self.emb_users.weight, emb_movies_final, self.emb_movies.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "254e9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loss\n",
    "def bpr_loss(emb_users_final, emb_users, emb_pos_movies_final, emb_pos_movies, emb_neg_movies_final, emb_neg_movies):\n",
    "  reg_loss = LAMBDA * (emb_users.norm().pow(2) +\n",
    "                       emb_pos_movies.norm().pow(2) +\n",
    "                       emb_neg_movies.norm().pow(2))\n",
    "  pos_ratings = torch.mul(emb_users_final, emb_pos_movies_final).sum(dim=-1)\n",
    "  neg_ratings = torch.mul(emb_users_final, emb_neg_movies_final).sum(dim=-1)\n",
    "  bpr_loss = torch.mean(torch.nn.functional.softplus(pos_ratings - neg_ratings))\n",
    "\n",
    "  return -bpr_loss + reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07752a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_items(edge_index):\n",
    "  user_items = dict()\n",
    "  for i in range(edge_index.shape[1]):\n",
    "    user = edge_index[0][i].item()\n",
    "    item = edge_index[1][i].item()\n",
    "    if user not in user_items:\n",
    "      user_items[user] = []\n",
    "    user_items[user].append(item)\n",
    "  return user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d003d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall_at_k(items_ground_truth, items_predicted):\n",
    "  num_correct_pred = np.sum(items_predicted, axis=1)\n",
    "  num_total_pred = np.array([len(items_ground_truth[i]) for i in range(len(items_ground_truth))])\n",
    "\n",
    "  recall = np.mean(num_correct_pred / num_total_pred)\n",
    "\n",
    "  return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f5f32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndcg_at_k(items_ground_truth, items_predicted):\n",
    "  test_matrix = np.zeros((len(items_predicted), K))\n",
    "\n",
    "  for i, items in enumerate(items_ground_truth):\n",
    "    length = min(len(items), K)\n",
    "    test_matrix[i, :length] = 1\n",
    "  \n",
    "  max_r = test_matrix\n",
    "  idcg = np.sum(max_r * 1. / np.log2(np.arange(2, K + 2)), axis=1)\n",
    "  dcg = items_predicted * (1. / np.log2(np.arange(2, K + 2)))\n",
    "  dcg = np.sum(dcg, axis=1)\n",
    "  idcg[idcg == 0.] = 1.\n",
    "  ndcg = dcg / idcg\n",
    "  ndcg[np.isnan(ndcg)] = 0.\n",
    "  \n",
    "  return np.mean(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38407ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to get evaluation metrics\n",
    "def get_metrics(model, edge_index, exclude_edge_indices):\n",
    "\n",
    "  ratings = torch.matmul(model.emb_users.weight, model.emb_movies.weight.T)\n",
    "\n",
    "  for exclude_edge_index in exclude_edge_indices:\n",
    "    user_pos_items = get_user_items(exclude_edge_index)\n",
    "    exclude_users = []\n",
    "    exclude_items = []\n",
    "    for user, items in user_pos_items.items():\n",
    "      exclude_users.extend([user] * len(items))\n",
    "      exclude_items.extend(items)\n",
    "    ratings[exclude_users, exclude_items] = -1024\n",
    "\n",
    "  # get the top k recommended items for each user\n",
    "  _, top_K_items = torch.topk(ratings, k=K)\n",
    "\n",
    "  # get all unique users in evaluated split\n",
    "  users = edge_index[0].unique()\n",
    "\n",
    "  test_user_pos_items = get_user_items(edge_index)\n",
    "\n",
    "  # convert test user pos items dictionary into a list\n",
    "  test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "  # determine the correctness of topk predictions\n",
    "  items_predicted = []\n",
    "  for user in users:\n",
    "    ground_truth_items = test_user_pos_items[user.item()]\n",
    "    label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "    items_predicted.append(label)\n",
    "\n",
    "  recall = compute_recall_at_k(test_user_pos_items_list, items_predicted)\n",
    "  ndcg = compute_ndcg_at_k(test_user_pos_items_list, items_predicted)\n",
    "\n",
    "  return recall, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b9e79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to evaluate model\n",
    "def test(model, edge_index, exclude_edge_indices):\n",
    "  emb_users_final, emb_users, emb_items_final, emb_items = model.forward(edge_index)\n",
    "  user_indices, pos_item_indices, neg_item_indices = structured_negative_sampling(edge_index, contains_neg_self_loops=False)\n",
    "\n",
    "  emb_users_final, emb_users = emb_users_final[user_indices], emb_users[user_indices]\n",
    "  emb_pos_items_final, emb_pos_items = emb_items_final[pos_item_indices], emb_items[pos_item_indices]\n",
    "  emb_neg_items_final, emb_neg_items = emb_items_final[neg_item_indices], emb_items[neg_item_indices]\n",
    "\n",
    "  loss = bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items).item()\n",
    "\n",
    "  recall, ndcg = get_metrics(model, edge_index, exclude_edge_indices)\n",
    "\n",
    "  return loss, recall, ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b03bed",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cba91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20\n",
    "LAMBDA = 1e-6\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "256a6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "model = LightGCN(num_users, num_movies)\n",
    "model = model.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc8c6199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train loss: -17.36334 | Val loss: -6.74925 | Val recall@20:0.10559 | Val ndcg@20: 0.10656\n",
      "Epoch 10 | Train loss: -66.57384 | Val loss: -26.11737 | Val recall@20:0.10667 | Val ndcg@20: 0.11183\n",
      "Epoch 15 | Train loss: -143.30582 | Val loss: -55.93231 | Val recall@20:0.10721 | Val ndcg@20: 0.11212\n",
      "Epoch 20 | Train loss: -263.75146 | Val loss: -95.26365 | Val recall@20:0.11006 | Val ndcg@20: 0.11351\n",
      "Epoch 25 | Train loss: -368.48038 | Val loss: -145.20323 | Val recall@20:0.11110 | Val ndcg@20: 0.11379\n",
      "Epoch 30 | Train loss: -477.84818 | Val loss: -200.85176 | Val recall@20:0.11053 | Val ndcg@20: 0.11375\n"
     ]
    }
   ],
   "source": [
    "num_batch = int(len(train_index) / BATCH_SIZE)\n",
    "for epoch in range(1, 31):\n",
    "  model.train()\n",
    "  for batch in range(num_batch):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    emb_users_final, emb_users, emb_movies_final, emb_movies = model.forward(train_edge_index)\n",
    "    \n",
    "    user_index, pos_movies_index, neg_movies_index = sample_mini_batch(train_edge_index)\n",
    "    \n",
    "    emb_users_final, emb_users = emb_users_final[user_index], emb_users[user_index]\n",
    "    emb_pos_movies_final, emb_pos_movies = emb_movies_final[pos_movies_index], emb_movies_final[pos_movies_index]\n",
    "    emb_neg_movies_final, emb_neg_movies = emb_movies_final[neg_movies_index], emb_movies_final[neg_movies_index]\n",
    "\n",
    "    train_loss = bpr_loss(emb_users_final, emb_users, emb_pos_movies_final, emb_pos_movies, emb_neg_movies_final, emb_neg_movies)\n",
    "    \n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "  if epoch % 5 == 0:\n",
    "    model.eval()\n",
    "    val_loss, recall, ndcg = test(model, val_edge_index, [train_edge_index])\n",
    "    print(f\"Epoch {epoch} | Train loss: {train_loss.item():.5f} | Val loss: {val_loss:.5f} | Val recall@{K}:{recall:.5f} | Val ndcg@{K}: {ndcg:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330a1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movie metadata\n",
    "movies_df = pd.read_csv('./dataset/ml-latest-small/movies.csv')\n",
    "\n",
    "# Reverse mapping to go from movie index to movieId\n",
    "index_to_movie_id = {index: movie_id for movie_id, index in movie_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation function\n",
    "def recommend_movies(model, user_id, train_edge_index, top_k=10):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        emb_users_final, _, emb_movies_final, _ = model.forward(train_edge_index)\n",
    "        \n",
    "        user_idx = user_map[user_id]\n",
    "        user_embedding = emb_users_final[user_idx]\n",
    "        \n",
    "        scores = torch.matmul(user_embedding, emb_movies_final.T)\n",
    "\n",
    "        rated_movie_indices = train_edge_index[1][train_edge_index[0] == user_idx]\n",
    "        scores[rated_movie_indices] = -1024\n",
    "\n",
    "        top_scores, top_movie_indices = torch.topk(scores, top_k)\n",
    "\n",
    "        top_movie_ids = [index_to_movie_id[idx.item()] for idx in top_movie_indices]\n",
    "        top_scores_list = top_scores.cpu().numpy().tolist()\n",
    "\n",
    "        recommendations = movies_df[movies_df['movieId'].isin(top_movie_ids)].copy()\n",
    "        \n",
    "        score_map = dict(zip(top_movie_ids, top_scores_list))\n",
    "        recommendations[\"score\"] = recommendations[\"movieId\"].map(score_map)\n",
    "\n",
    "        recommendations = recommendations.sort_values(by=\"score\", ascending=False)\n",
    "\n",
    "        return recommendations[['movieId', 'title', 'genres', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id = 1\n",
    "recommendations = recommend_movies(model, test_user_id, train_edge_index, top_k=10)\n",
    "print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
